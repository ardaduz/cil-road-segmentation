{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ODNLPGHKKgr-"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import zipfile\n",
    "import functools\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['axes.grid'] = False\n",
    "mpl.rcParams['figure.figsize'] = (12,12)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.image as mpimg\n",
    "import pandas as pd\n",
    "import imageio\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YQ9VRReUQxXi"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.contrib as tfcontrib\n",
    "from tensorflow.python.keras import layers\n",
    "from tensorflow.python.keras import losses\n",
    "from tensorflow.python.keras import models\n",
    "from tensorflow.python.keras import backend as K\n",
    "\n",
    "tf.set_random_seed(753)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wT1kb3q0ghhi"
   },
   "outputs": [],
   "source": [
    "img_dir = '../competition-data/training/images'\n",
    "label_dir = '../competition-data/training/groundtruth'\n",
    "test_dir = '../competition-data/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DtutNudKbf70"
   },
   "outputs": [],
   "source": [
    "train_filenames = os.listdir(img_dir)\n",
    "x_train_filenames = [os.path.join(img_dir, filename) for filename in train_filenames]\n",
    "y_train_filenames = [os.path.join(label_dir, filename) for filename in train_filenames]\n",
    "test_filenames = os.listdir(test_dir)\n",
    "x_test_filenames = [os.path.join(test_dir, filename) for filename in test_filenames]\n",
    "\n",
    "x_train_filenames, x_val_filenames, y_train_filenames, y_val_filenames = train_test_split(x_train_filenames, y_train_filenames, test_size=0.2)\n",
    "#kFold = KFold(n=len(x_train_filenames), n_folds=5, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zDycQekHaMqq"
   },
   "outputs": [],
   "source": [
    "num_train_examples = len(x_train_filenames)\n",
    "num_val_examples = len(x_val_filenames)\n",
    "num_test_examples = len(x_test_filenames)\n",
    "\n",
    "print(\"Number of training examples: {}\".format(num_train_examples))\n",
    "print(\"Number of validation examples: {}\".format(num_val_examples))\n",
    "print(\"Number of test examples: {}\".format(num_test_examples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Nhda5fkPS3JD"
   },
   "source": [
    "### Debug Output: Image paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Di1N83ArilzR"
   },
   "outputs": [],
   "source": [
    "x_train_filenames[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Gc-BDv1Zio1z"
   },
   "outputs": [],
   "source": [
    "y_train_filenames[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mhvDoZkbcUa1"
   },
   "source": [
    "### Debug Output: x_train and y_train images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qUA6SDLhozjj"
   },
   "outputs": [],
   "source": [
    "display_num = 2\n",
    "\n",
    "r_choices = np.random.choice(num_train_examples, display_num)\n",
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "for i in range(0, display_num * 2, 2):\n",
    "  img_num = r_choices[i // 2]\n",
    "  x_pathname = x_train_filenames[img_num]\n",
    "  y_pathname = y_train_filenames[img_num]\n",
    "\n",
    "  plt.subplot(display_num, 2, i + 1)\n",
    "  plt.imshow(mpimg.imread(x_pathname), cmap=\"gray\")  \n",
    "  plt.subplot(display_num, 2, i + 2)\n",
    "  plt.imshow(mpimg.imread(y_pathname), cmap=\"gray\")\n",
    "\n",
    "plt.suptitle(\"Examples of Images and their Segmentations\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d4CPgvPiToB_"
   },
   "source": [
    "# Preprocessing pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oeDoiSFlothe"
   },
   "outputs": [],
   "source": [
    "img_shape = (256, 256, 3)\n",
    "batch_size = 3\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Fb_psznAggwr"
   },
   "outputs": [],
   "source": [
    "def _process_pathnames(fname, label_path):\n",
    "  \"\"\"Load the image pair from given paths\"\"\"\n",
    "  # We map this function onto each pathname pair  \n",
    "\n",
    "  img_str = tf.read_file(fname)\n",
    "  img = tf.image.decode_png(img_str, channels=3)\n",
    "\n",
    "  label_img_str = tf.read_file(label_path)\n",
    "  label_img = tf.image.decode_png(label_img_str, channels=1)\n",
    "  return img, label_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y4UE28JiCuOk"
   },
   "source": [
    "## Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xdY046OqtGVH"
   },
   "outputs": [],
   "source": [
    "def shift_img(output_img, label_img, width_shift_range, height_shift_range):\n",
    "  \"\"\"This fn will perform the horizontal or vertical shift\"\"\"\n",
    "  if width_shift_range or height_shift_range:\n",
    "    if width_shift_range:\n",
    "      width_shift_range = tf.random_uniform([], \n",
    "                                            -width_shift_range * img_shape[1],\n",
    "                                            width_shift_range * img_shape[1],\n",
    "                                            seed=753)\n",
    "    if height_shift_range:\n",
    "      height_shift_range = tf.random_uniform([],\n",
    "                                             -height_shift_range * img_shape[0],\n",
    "                                             height_shift_range * img_shape[0],\n",
    "                                             seed=753)\n",
    "    # Translate both \n",
    "    output_img = tfcontrib.image.translate(output_img,\n",
    "                                           [width_shift_range, height_shift_range])\n",
    "    label_img = tfcontrib.image.translate(label_img,\n",
    "                                          [width_shift_range, height_shift_range])\n",
    "  return output_img, label_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OogLSplstur9"
   },
   "outputs": [],
   "source": [
    "def flip_img(horizontal_flip, tr_img, label_img):\n",
    "  \"\"\"Flip the image randomly\"\"\"\n",
    "  if horizontal_flip:\n",
    "    flip_prob = tf.random_uniform([], 0.0, 1.0, seed=753)\n",
    "    tr_img, label_img = tf.cond(tf.less(flip_prob, 0.5),\n",
    "                                lambda: (tf.image.flip_left_right(tr_img), tf.image.flip_left_right(label_img)),\n",
    "                                lambda: (tr_img, label_img))\n",
    "  return tr_img, label_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OogLSplstur9"
   },
   "outputs": [],
   "source": [
    "def rot90_img(rotate90, tr_img, label_img):\n",
    "  \"\"\"Rotating the image randomly in 90° angles\"\"\"\n",
    "  if rotate90:\n",
    "    rotate_count = tf.random_uniform([], 0, 4, dtype=tf.dtypes.int32, seed=753)\n",
    "    tr_img = tf.image.rot90(tr_img, rotate_count)\n",
    "    label_img = tf.image.rot90(label_img, rotate_count)\n",
    "\n",
    "  return tr_img, label_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "18WA0Sl3olyn"
   },
   "outputs": [],
   "source": [
    "def _augment(img,\n",
    "             label_img,\n",
    "             resize=None,  # Resize the image to some size e.g. [256, 256]\n",
    "             scale=1,  # Scale image e.g. 1 / 255.\n",
    "             hue_delta=0,  # Adjust the hue of an RGB image by random factor\n",
    "             horizontal_flip=False,  # Random left right flip,\n",
    "             rotate90=False,  # Random number of 90° rotations\n",
    "             width_shift_range=0,  # Randomly translate the image horizontally\n",
    "             height_shift_range=0):  # Randomly translate the image vertically \n",
    "  if resize is not None:\n",
    "    # Resize both images\n",
    "    label_img = tf.image.resize_images(label_img, resize)\n",
    "    img = tf.image.resize_images(img, resize)\n",
    "\n",
    "  if hue_delta:\n",
    "    img = tf.image.random_hue(img, hue_delta, seed=753)\n",
    "\n",
    "  img, label_img = flip_img(horizontal_flip, img, label_img)\n",
    "  img, label_img = rot90_img(rotate90, img, label_img)\n",
    "  #img, label_img = shift_img(img, label_img, width_shift_range, height_shift_range)\n",
    "  label_img = tf.cast(label_img, tf.dtypes.float32) * scale\n",
    "  img = tf.cast(img, tf.dtypes.float32) * scale \n",
    "  return img, label_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tkNqQaR2HQbd"
   },
   "outputs": [],
   "source": [
    "def get_baseline_dataset(filenames, \n",
    "                         labels,\n",
    "                         preproc_fn=functools.partial(_augment),\n",
    "                         threads=5, \n",
    "                         batch_size=batch_size,\n",
    "                         shuffle=True,\n",
    "                         repeat=True):           \n",
    "  num_x = len(filenames)\n",
    "  # Create a dataset from the filenames and labels\n",
    "  dataset = tf.data.Dataset.from_tensor_slices((filenames, labels))\n",
    "  # Map our preprocessing function to every element in our dataset, taking\n",
    "  # advantage of multithreading\n",
    "  dataset = dataset.map(_process_pathnames, num_parallel_calls=1)\n",
    "  \n",
    "  if preproc_fn.keywords is not None and 'resize' not in preproc_fn.keywords:\n",
    "    assert batch_size == 1, \"Batching images must be of the same size\"\n",
    "\n",
    "  dataset = dataset.map(preproc_fn, num_parallel_calls=threads)\n",
    "\n",
    "  if shuffle:\n",
    "    dataset = dataset.shuffle(num_x, seed=753)\n",
    "\n",
    "  # It's necessary to repeat our data for all epochs\n",
    "  if repeat:\n",
    "    dataset = dataset.repeat()\n",
    "\n",
    "  dataset = dataset.batch(batch_size)\n",
    "    \n",
    "  return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zwtgius5CRKc"
   },
   "source": [
    "## Set up train and validation datasets\n",
    "Note that we apply image augmentation to our training dataset but not our validation dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iu5WmYmOwKrV"
   },
   "outputs": [],
   "source": [
    "tr_cfg = {\n",
    "  'resize': [img_shape[0], img_shape[1]],\n",
    "  'scale': 1 / 255.,\n",
    "  'horizontal_flip': True,\n",
    "  'rotate90': True,\n",
    "}\n",
    "tr_preprocessing_fn = functools.partial(_augment, **tr_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RtzLkDFMpF0T"
   },
   "outputs": [],
   "source": [
    "val_cfg = {\n",
    "  'resize': [img_shape[0], img_shape[1]],\n",
    "  'scale': 1 / 255.,\n",
    "}\n",
    "val_preprocessing_fn = functools.partial(_augment, **val_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5cNpECdkaafo"
   },
   "outputs": [],
   "source": [
    "train_ds = get_baseline_dataset(x_train_filenames,\n",
    "                                y_train_filenames,\n",
    "                                preproc_fn=tr_preprocessing_fn,\n",
    "                                batch_size=batch_size)\n",
    "val_ds = get_baseline_dataset(x_val_filenames,\n",
    "                              y_val_filenames, \n",
    "                              preproc_fn=val_preprocessing_fn,\n",
    "                              batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Yasuvr5IbFlM"
   },
   "source": [
    "### Debug Output: Preprocessing pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hjoUqbPdHQej"
   },
   "outputs": [],
   "source": [
    "temp_ds = get_baseline_dataset(x_train_filenames, \n",
    "                               y_train_filenames,\n",
    "                               preproc_fn=tr_preprocessing_fn,\n",
    "                               batch_size=1,\n",
    "                               shuffle=False)\n",
    "# Let's examine some of these augmented images\n",
    "data_aug_iter = temp_ds.make_one_shot_iterator()\n",
    "next_element = data_aug_iter.get_next()\n",
    "with tf.Session() as sess: \n",
    "  batch_of_imgs, label = sess.run(next_element)\n",
    "\n",
    "  # Running next element in our graph will produce a batch of images\n",
    "  plt.figure(figsize=(10, 10))\n",
    "  img = batch_of_imgs[0]\n",
    "\n",
    "  plt.subplot(1, 2, 1)\n",
    "  plt.imshow(img)\n",
    "\n",
    "  plt.subplot(1, 2, 2)\n",
    "  plt.imshow(label[0, :, :, 0], cmap='gray')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define our neural network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zfew1i1F6bK-"
   },
   "outputs": [],
   "source": [
    "def conv_block(input_tensor, num_filters):\n",
    "  encoder = layers.Conv2D(num_filters, (3, 3), padding='same')(input_tensor)\n",
    "  encoder = layers.BatchNormalization()(encoder)\n",
    "  encoder = layers.Activation('relu')(encoder)\n",
    "  encoder = layers.Conv2D(num_filters, (3, 3), padding='same')(encoder)\n",
    "  encoder = layers.BatchNormalization()(encoder)\n",
    "  encoder = layers.Activation('relu')(encoder)\n",
    "  return encoder\n",
    "\n",
    "def encoder_block(input_tensor, num_filters):\n",
    "  encoder = conv_block(input_tensor, num_filters)\n",
    "  encoder_pool = layers.MaxPooling2D((2, 2), strides=(2, 2))(encoder)\n",
    "  \n",
    "  return encoder_pool, encoder\n",
    "\n",
    "def decoder_block(input_tensor, concat_tensor, num_filters):\n",
    "  decoder = layers.Conv2DTranspose(num_filters, (2, 2), strides=(2, 2), padding='same')(input_tensor)\n",
    "  decoder = layers.concatenate([concat_tensor, decoder], axis=-1)\n",
    "  decoder = layers.BatchNormalization()(decoder)\n",
    "  decoder = layers.Activation('relu')(decoder)\n",
    "  decoder = layers.Conv2D(num_filters, (3, 3), padding='same')(decoder)\n",
    "  decoder = layers.BatchNormalization()(decoder)\n",
    "  decoder = layers.Activation('relu')(decoder)\n",
    "  decoder = layers.Conv2D(num_filters, (3, 3), padding='same')(decoder)\n",
    "  decoder = layers.BatchNormalization()(decoder)\n",
    "  decoder = layers.Activation('relu')(decoder)\n",
    "  return decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xRLp21S_hpTn"
   },
   "outputs": [],
   "source": [
    "inputs = layers.Input(shape=img_shape)\n",
    "# 256\n",
    "\n",
    "encoder0_pool, encoder0 = encoder_block(inputs, 32)\n",
    "# 128\n",
    "\n",
    "encoder1_pool, encoder1 = encoder_block(encoder0_pool, 64)\n",
    "# 64\n",
    "\n",
    "encoder2_pool, encoder2 = encoder_block(encoder1_pool, 128)\n",
    "# 32\n",
    "\n",
    "encoder3_pool, encoder3 = encoder_block(encoder2_pool, 256)\n",
    "# 16\n",
    "\n",
    "encoder4_pool, encoder4 = encoder_block(encoder3_pool, 512)\n",
    "# 8\n",
    "\n",
    "center = conv_block(encoder4_pool, 1024)\n",
    "# center\n",
    "\n",
    "decoder4 = decoder_block(center, encoder4, 512)\n",
    "# 16\n",
    "\n",
    "decoder3 = decoder_block(decoder4, encoder3, 256)\n",
    "# 32\n",
    "\n",
    "decoder2 = decoder_block(decoder3, encoder2, 128)\n",
    "# 64\n",
    "\n",
    "decoder1 = decoder_block(decoder2, encoder1, 64)\n",
    "# 128\n",
    "\n",
    "decoder0 = decoder_block(decoder1, encoder0, 32)\n",
    "# 256\n",
    "\n",
    "outputs = layers.Conv2D(1, (1, 1), activation='sigmoid')(decoder0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "76QkTzXVczgc"
   },
   "outputs": [],
   "source": [
    "model = models.Model(inputs=[inputs], outputs=[outputs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sfuBVut0fogM"
   },
   "source": [
    "Dice loss is a metric that measures overlap. More info on optimizing for Dice coefficient (our dice loss) can be found in the [paper](http://campar.in.tum.de/pub/milletari2016Vnet/milletari2016Vnet.pdf), where it was introduced. \n",
    "\n",
    "We use dice loss here because it performs better at class imbalanced problems by design. In addition, maximizing the dice coefficient and IoU metrics are the actual objectives and goals of our segmentation task. Using cross entropy is more of a proxy which is easier to maximize. Instead, we maximize our objective directly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t_8_hbHECUAW"
   },
   "outputs": [],
   "source": [
    "def dice_coeff(y_true, y_pred):\n",
    "  smooth = 1.\n",
    "  # Flatten\n",
    "  y_true_f = tf.reshape(y_true, [-1])\n",
    "  y_pred_f = tf.reshape(y_pred, [-1])\n",
    "  intersection = tf.reduce_sum(y_true_f * y_pred_f)\n",
    "  score = (2. * intersection + smooth) / (tf.reduce_sum(y_true_f) + tf.reduce_sum(y_pred_f) + smooth)\n",
    "  return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4DgINhlpNaxP"
   },
   "outputs": [],
   "source": [
    "def dice_loss(y_true, y_pred):\n",
    "  loss = 1 - dice_coeff(y_true, y_pred)\n",
    "  return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qqClGNFJdANU"
   },
   "source": [
    "Here, we'll use a specialized loss function that combines binary cross entropy and our dice loss. This is based on [individuals who competed within this competition obtaining better results empirically](https://www.kaggle.com/c/carvana-image-masking-challenge/discussion/40199). Try out your own custom losses to measure performance (e.g. bce + log(dice_loss), only bce, etc.)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "udrfi9JGB-bL"
   },
   "outputs": [],
   "source": [
    "def bce_dice_loss(y_true, y_pred):\n",
    "  loss = losses.binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n",
    "  return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def root_mean_squared_error(y_true, y_pred):\n",
    "  loss = tf.sqrt(losses.mean_squared_error(y_true, y_pred))\n",
    "  return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LifmpjXNc9Gz"
   },
   "source": [
    "## Compile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gflcWk2Cc8Bi",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', \n",
    "              loss=bce_dice_loss, \n",
    "              metrics=[dice_loss, root_mean_squared_error])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1nHnj6199elZ"
   },
   "outputs": [],
   "source": [
    "save_model_path = 'weights_epoch{epoch:03d}_rmse{val_root_mean_squared_error:.4f}.hdf5'\n",
    "cp = tf.keras.callbacks.ModelCheckpoint(filepath=save_model_path, monitor='val_root_mean_squared_error', save_best_only=True, verbose=1)\n",
    "es = tf.keras.callbacks.EarlyStopping(monitor='val_root_mean_squared_error', min_delta=0.01, patience=20, verbose=1, mode='auto', restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vJP_EvuTb4hH"
   },
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UMZcOrq5aaj1",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model.fit(train_ds, \n",
    "                    steps_per_epoch=int(np.ceil(num_train_examples / float(batch_size))),\n",
    "                    epochs=epochs,\n",
    "                    validation_data=val_ds,\n",
    "                    validation_steps=int(np.ceil(num_val_examples / float(batch_size))),\n",
    "                    callbacks=[cp, es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AvntxymYn8rM",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rmse = history.history['root_mean_squared_error']\n",
    "val_rmse = history.history['val_root_mean_squared_error']\n",
    "\n",
    "dice = history.history['dice_loss']\n",
    "val_dice = history.history['val_dice_loss']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(len(loss))\n",
    "\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(epochs_range, dice, label='Training Dice Loss')\n",
    "plt.plot(epochs_range, val_dice, label='Validation Dice Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Dice Loss')\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.plot(epochs_range, rmse, label='Training RMSE')\n",
    "plt.plot(epochs_range, val_rmse, label='Validation RMSE')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation RMSE Loss')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MGFKf8yCTYbw"
   },
   "source": [
    "# Qualitative evaluation of our performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5Ph7acmrCXm6"
   },
   "outputs": [],
   "source": [
    "# Load weights from latest checkpoint\n",
    "model_path = sorted(glob.glob('weights*'), reverse=True)[0]\n",
    "model = models.load_model(model_path, custom_objects={'root_mean_squared_error': root_mean_squared_error,\n",
    "                                                           'bce_dice_loss': bce_dice_loss,\n",
    "                                                           'dice_loss': dice_loss})\n",
    "# Alternatively, load the weights directly: \n",
    "#model.load_weights(model_path)\n",
    "print(\"Loaded model from:\", model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0GnwZ7CPaamI"
   },
   "outputs": [],
   "source": [
    "# Visualize some of the outputs \n",
    "data_aug_iter = val_ds.make_one_shot_iterator()\n",
    "next_element = data_aug_iter.get_next()\n",
    "\n",
    "# Running next element in our graph will produce a batch of images\n",
    "plt.figure(figsize=(10, 20))\n",
    "for i in range(5):\n",
    "  batch_of_imgs, label = tf.keras.backend.get_session().run(next_element)\n",
    "  img = batch_of_imgs[0]\n",
    "  predicted_label = model.predict(batch_of_imgs)[0]\n",
    "\n",
    "  plt.subplot(5, 3, 3 * i + 1)\n",
    "  plt.imshow(img)\n",
    "  plt.title(\"Input image\")\n",
    "  \n",
    "  plt.subplot(5, 3, 3 * i + 2)\n",
    "  plt.imshow(label[0, :, :, 0], cmap='gray')\n",
    "  plt.title(\"Actual Mask\")\n",
    "  plt.subplot(5, 3, 3 * i + 3)\n",
    "  plt.imshow(predicted_label[:, :, 0], cmap='gray')\n",
    "  plt.title(\"Predicted Mask\")\n",
    "plt.suptitle(\"Examples of Input Image, Label, and Prediction\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create test set predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create directory for predictions\n",
    "prediction_dir = model_path\n",
    "prediction_dir = prediction_dir.replace(\"weights\", \"predictions\", 1).replace(\".hdf5\", \"\", 1)\n",
    "os.mkdir(prediction_dir)\n",
    "\n",
    "test_ds = get_baseline_dataset(x_test_filenames,\n",
    "                               x_test_filenames, \n",
    "                               preproc_fn=val_preprocessing_fn,\n",
    "                               batch_size=batch_size,\n",
    "                               shuffle=False,\n",
    "                               repeat=False)\n",
    "\n",
    "data_aug_iter = test_ds.make_one_shot_iterator()\n",
    "next_element = data_aug_iter.get_next()\n",
    "count=0\n",
    "\n",
    "sess = tf.keras.backend.get_session()\n",
    "try:\n",
    "  while True:\n",
    "    batch_of_imgs, label = sess.run(next_element)\n",
    "    predicted_labels = model.predict(batch_of_imgs)\n",
    "    \n",
    "    # rescale images from [0, 1] to [0, 255]\n",
    "    predicted_labels = predicted_labels / val_cfg['scale']\n",
    "\n",
    "    for i in range(len(predicted_labels)):\n",
    "      pred = Image.fromarray(predicted_labels[i, :, :, 0], 'F').resize((608, 608)).convert('L')\n",
    "      imageio.imwrite(os.path.join(prediction_dir, test_filenames[count]), pred)\n",
    "      count += 1\n",
    "\n",
    "except tf.errors.OutOfRangeError:\n",
    "  pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show some of the predictions\n",
    "display_num = 4\n",
    "\n",
    "r_choices = np.random.choice(len(test_filenames), display_num)\n",
    "plt.figure(figsize=(10, 20))\n",
    "\n",
    "for i in range(0, display_num * 2, 2):\n",
    "  img_num = r_choices[i // 2]\n",
    "  x_pathname = x_test_filenames[img_num]\n",
    "  y_pathname = os.path.join(prediction_dir, test_filenames[img_num])\n",
    "\n",
    "  plt.subplot(display_num, 2, i + 1)\n",
    "  plt.imshow(mpimg.imread(x_pathname), cmap=\"gray\")  \n",
    "  plt.subplot(display_num, 2, i + 2)\n",
    "  plt.imshow(mpimg.imread(y_pathname), cmap=\"gray\")\n",
    "\n",
    "plt.suptitle(\"Examples of images and their predicted segmentations\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mask to submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foreground_threshold = 0.25 # percentage of pixels > 1 required to assign a foreground label to a patch\n",
    "\n",
    "# assign a label to a patch\n",
    "def patch_to_label(patch):\n",
    "  df = np.mean(patch)\n",
    "  if df > foreground_threshold:\n",
    "    return 1\n",
    "  else:\n",
    "    return 0\n",
    "\n",
    "\n",
    "def mask_to_submission_strings(image_filename):\n",
    "  \"\"\"Reads a single image and outputs the strings that should go into the submission file\"\"\"\n",
    "  img_number = int(re.search(r\"\\d+(?=\\.png$)\", image_filename).group(0))\n",
    "  im = mpimg.imread(image_filename)\n",
    "  patch_size = 16\n",
    "  for j in range(0, im.shape[1], patch_size):\n",
    "    for i in range(0, im.shape[0], patch_size):\n",
    "      patch = im[i:i + patch_size, j:j + patch_size]\n",
    "      label = patch_to_label(patch)\n",
    "      yield(\"{:03d}_{}_{},{}\".format(img_number, j, i, label))\n",
    "\n",
    "\n",
    "def masks_to_submission(submission_filename, *image_filenames):\n",
    "  \"\"\"Converts images into a submission file\"\"\"\n",
    "  with open(submission_filename, 'w') as f:\n",
    "    f.write('id,prediction\\n')\n",
    "    for fn in image_filenames[0:]:\n",
    "      f.writelines('{}\\n'.format(s) for s in mask_to_submission_strings(fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_filename = model_path.replace(\"weights\", \"submission\", 1).replace(\".hdf5\", \".csv\", 1)\n",
    "image_filenames = [os.path.join(prediction_dir, filename) for filename in os.listdir(prediction_dir)]\n",
    "masks_to_submission(submission_filename, *image_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Validating submission file:\", submission_filename)\n",
    "df = pd.read_csv(submission_filename)\n",
    "\n",
    "print('Shape of csv:', df.shape)\n",
    "assert df.shape == (135736, 2), \"Invalid number of rows or columns in submission file!\"\n",
    "assert df['id'].unique().size == 135736, \"Column 'id' should contain 135736 unique values!\"\n",
    "\n",
    "meanPred = df['prediction'].mean()\n",
    "print(\"Mean prediction: {:.3f}\".format(meanPred))\n",
    "assert meanPred > 0.05 and meanPred < 0.3, \"Very unlikely mean prediction!\"\n",
    "\n",
    "print(\"Submission file looks OKAY!\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Image Segmentation",
   "private_outputs": true,
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
