{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ODNLPGHKKgr-"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import zipfile\n",
    "import functools\n",
    "import re\n",
    "import time\n",
    "import shutil\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "#mpl.rcParams['axes.grid'] = False\n",
    "mpl.rcParams['figure.figsize'] = (12,12)\n",
    "\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "import matplotlib.image as mpimg\n",
    "from matplotlib.colors import Normalize\n",
    "import pandas as pd\n",
    "import imageio\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YQ9VRReUQxXi"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.contrib as tfcontrib\n",
    "from tensorflow.python.keras import layers\n",
    "from tensorflow.python.keras import losses\n",
    "from tensorflow.python.keras import models\n",
    "from tensorflow.python.keras import backend as K\n",
    "from tensorflow.python.keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom TensorBoard callback taken from https://stackoverflow.com/a/48393723\n",
    "\n",
    "class TrainValTensorBoard(TensorBoard):\n",
    "    def __init__(self, log_dir='./logs', **kwargs):\n",
    "        # Make the original `TensorBoard` log to a subdirectory 'training'\n",
    "        training_log_dir = os.path.join(log_dir, 'training')\n",
    "        super(TrainValTensorBoard, self).__init__(training_log_dir, **kwargs)\n",
    "\n",
    "        # Log the validation metrics to a separate subdirectory\n",
    "        self.val_log_dir = os.path.join(log_dir, 'validation')\n",
    "\n",
    "    def set_model(self, model):\n",
    "        # Setup writer for validation metrics\n",
    "        self.val_writer = tf.summary.FileWriter(self.val_log_dir)\n",
    "        super(TrainValTensorBoard, self).set_model(model)\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        # Pop the validation logs and handle them separately with\n",
    "        # `self.val_writer`. Also rename the keys so that they can\n",
    "        # be plotted on the same figure with the training metrics\n",
    "        logs = logs or {}\n",
    "        \n",
    "        # Pass the non-validation logs to `TensorBoard.on_epoch_end`\n",
    "        train_logs = {k: v for k, v in logs.items() if not k.startswith('val_')}\n",
    "        super(TrainValTensorBoard, self).on_epoch_end(epoch, train_logs)\n",
    "        \n",
    "        val_logs = {k.replace('val_', 'epoch_'): v for k, v in logs.items() if k.startswith('val_')}\n",
    "        for name, value in val_logs.items():\n",
    "            summary = tf.Summary()\n",
    "            summary_value = summary.value.add()\n",
    "            summary_value.simple_value = value.item()\n",
    "            summary_value.tag = name\n",
    "            self.val_writer.add_summary(summary, epoch)\n",
    "        self.val_writer.flush()\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        super(TrainValTensorBoard, self).on_train_end(logs)\n",
    "        self.val_writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d4CPgvPiToB_"
   },
   "source": [
    "# Preprocessing pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oeDoiSFlothe"
   },
   "outputs": [],
   "source": [
    "img_shape = [256, 256, 3]\n",
    "batch_size = 3\n",
    "epochs = 100\n",
    "cv_splits = 1\n",
    "\n",
    "DEBUG_OUTPUT = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Fb_psznAggwr"
   },
   "outputs": [],
   "source": [
    "def _process_pathnames(fname, label_path):\n",
    "  \"\"\"Load the image pair from given paths\"\"\"\n",
    "  # We map this function onto each pathname pair  \n",
    "  img_str = tf.read_file(fname)\n",
    "  img = tf.image.decode_png(img_str, channels=3)\n",
    "\n",
    "  label_img_str = tf.read_file(label_path)\n",
    "  label_img = tf.image.decode_png(label_img_str, channels=1)\n",
    "  \n",
    "  return img, label_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y4UE28JiCuOk"
   },
   "source": [
    "### Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "18WA0Sl3olyn"
   },
   "outputs": [],
   "source": [
    "def _augment(img,\n",
    "             label_img,\n",
    "             resize=None, \n",
    "             scale=1,\n",
    "             hue_delta=0,\n",
    "             contrast_factor_upper_bound = 1,\n",
    "             saturation_factor_upper_bound = 1,\n",
    "             horizontal_flip=False,             \n",
    "             vertical_flip=False,\n",
    "             rotate90=False):\n",
    "  \"\"\"Apply data augmentation\"\"\"\n",
    "  \n",
    "  # Resize\n",
    "  if resize is not None:\n",
    "    img = tf.image.resize_images(img, resize)\n",
    "    label_img = tf.image.resize_images(label_img, resize)\n",
    "    \n",
    "  # Scale\n",
    "  img = tf.cast(img, tf.dtypes.float32) * scale\n",
    "  label_img = tf.cast(label_img, tf.dtypes.float32) * scale\n",
    "  \n",
    "  # Hue\n",
    "  if hue_delta > 0:\n",
    "    img = tf.image.random_hue(img, max_delta=hue_delta)\n",
    "    \n",
    "  # Contrast\n",
    "  if contrast_factor_upper_bound != 1:\n",
    "    lower_bound = 1 / float(contrast_factor_upper_bound)\n",
    "    img = tf.image.random_contrast(img, lower=lower_bound, upper=contrast_factor_upper_bound)\n",
    "    \n",
    "  # Saturation\n",
    "  if saturation_factor_upper_bound != 1:\n",
    "    lower_bound = 1 / float(saturation_factor_upper_bound)\n",
    "    img = tf.image.random_saturation(img, lower=lower_bound, upper=saturation_factor_upper_bound)\n",
    "    \n",
    "  # Ensure images are in [0, 1] range\n",
    "  img = tf.minimum(tf.maximum(img, 0.0), 1.0)\n",
    "    \n",
    "  # Horizontal flip\n",
    "  if horizontal_flip:\n",
    "    flip_prob = tf.random_uniform([], 0.0, 1.0)\n",
    "    img, label_img = tf.cond(tf.less(flip_prob, 0.5),\n",
    "                                lambda: (tf.image.flip_left_right(img), tf.image.flip_left_right(label_img)),\n",
    "                                lambda: (img, label_img))\n",
    "  \n",
    "  # Vertical flip\n",
    "  if vertical_flip:\n",
    "    flip_prob = tf.random_uniform([], 0.0, 1.0)\n",
    "    img, label_img = tf.cond(tf.less(flip_prob, 0.5),\n",
    "                                lambda: (tf.image.flip_up_down(img), tf.image.flip_up_down(label_img)),\n",
    "                                lambda: (img, label_img))\n",
    "  \n",
    "  # Random 90Â° rotations\n",
    "  if rotate90:\n",
    "    rotate_count = tf.random_uniform([], 0, 4, dtype=tf.dtypes.int32)\n",
    "    img = tf.image.rot90(img, rotate_count)\n",
    "    label_img = tf.image.rot90(label_img, rotate_count)\n",
    "  \n",
    "  return img, label_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tkNqQaR2HQbd"
   },
   "outputs": [],
   "source": [
    "def get_baseline_dataset(filenames, \n",
    "                         labels,\n",
    "                         preproc_fn=functools.partial(_augment),\n",
    "                         threads=6, \n",
    "                         batch_size=batch_size,\n",
    "                         shuffle=True,\n",
    "                         repeat=True):           \n",
    "  num_x = len(filenames)\n",
    "  # Create a dataset from the filenames and labels\n",
    "  dataset = tf.data.Dataset.from_tensor_slices((filenames, labels))\n",
    "  dataset = dataset.map(_process_pathnames, num_parallel_calls=threads)\n",
    "  dataset = dataset.map(preproc_fn, num_parallel_calls=threads)\n",
    "  \n",
    "  if shuffle:\n",
    "    dataset = dataset.shuffle(num_x)\n",
    "  \n",
    "  dataset = dataset.batch(batch_size)\n",
    "  \n",
    "  # It's necessary to repeat our data for all epochs\n",
    "  if repeat:\n",
    "    dataset = dataset.repeat()    \n",
    "  \n",
    "  dataset = dataset.prefetch(1)\n",
    "  \n",
    "  return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wT1kb3q0ghhi"
   },
   "outputs": [],
   "source": [
    "img_dir = '../competition-data/training/images'\n",
    "label_dir = '../competition-data/training/groundtruth'\n",
    "test_dir = '../competition-data/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DtutNudKbf70"
   },
   "outputs": [],
   "source": [
    "train_filenames = os.listdir(img_dir)\n",
    "x_train_filenames = np.array([os.path.join(img_dir, filename) for filename in train_filenames])\n",
    "y_train_filenames = np.array([os.path.join(label_dir, filename) for filename in train_filenames])\n",
    "test_filenames = os.listdir(test_dir)\n",
    "x_test_filenames = np.array([os.path.join(test_dir, filename) for filename in test_filenames])\n",
    "\n",
    "print(\"Number of training examples: {}\".format(len(x_train_filenames)))\n",
    "print(\"Number of test examples: {}\".format(len(x_test_filenames)))\n",
    "\n",
    "data_splits = []\n",
    "\n",
    "if cv_splits > 1:\n",
    "  kFold = KFold(n_splits=cv_splits, shuffle=True)\n",
    "  data_splits = [(train, val) for train, val in kFold.split(x_train_filenames)]\n",
    "else:\n",
    "  train, val = train_test_split(range(len(x_train_filenames)), test_size=0.2)\n",
    "  data_splits = [(np.array(train), np.array(val))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Nhda5fkPS3JD"
   },
   "source": [
    "### Debug Output: Image paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Di1N83ArilzR"
   },
   "outputs": [],
   "source": [
    "if DEBUG_OUTPUT:\n",
    "  print(\"Training images:\\n\", x_train_filenames[:5])\n",
    "  print(\"Training labels:\\n\", y_train_filenames[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mhvDoZkbcUa1"
   },
   "source": [
    "### Debug Output: x_train and y_train images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qUA6SDLhozjj"
   },
   "outputs": [],
   "source": [
    "if DEBUG_OUTPUT:\n",
    "  display_num = 2\n",
    "\n",
    "  r_choices = np.random.choice(len(x_train_filenames), display_num)\n",
    "  plt.figure(figsize=(10, 10))\n",
    "\n",
    "  for i in range(0, display_num * 2, 2):\n",
    "    img_num = r_choices[i // 2]\n",
    "    x_pathname = x_train_filenames[img_num]\n",
    "    y_pathname = y_train_filenames[img_num]\n",
    "\n",
    "    plt.subplot(display_num, 2, i + 1)\n",
    "    plt.imshow(mpimg.imread(x_pathname), cmap=\"gray\")  \n",
    "    plt.subplot(display_num, 2, i + 2)\n",
    "    plt.imshow(mpimg.imread(y_pathname), cmap=\"gray\")\n",
    "\n",
    "  plt.suptitle(\"Examples of Images and their Segmentations\")\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zwtgius5CRKc"
   },
   "source": [
    "## Set up train and validation datasets\n",
    "Note that we apply image augmentation to our training dataset but not our validation dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iu5WmYmOwKrV"
   },
   "outputs": [],
   "source": [
    "tr_cfg = {\n",
    "  # Resize input images (and label images)\n",
    "  'resize': [img_shape[0], img_shape[1]],\n",
    "  # Adjust value range by a scale factor\n",
    "  'scale': 1 / 255.,\n",
    "  # Adjust the hue of an RGB image by random factor choosen in range [-delta, delta]. Default: 0.0\n",
    "  'hue_delta': 0.1,\n",
    "  # Random contrast_factor choosen in range [1/upper_bound, upper_bound]. Default: 1.0\n",
    "  'contrast_factor_upper_bound': 1.33,\n",
    "  # Random saturation_factor choosen in range [1/upper_bound, upper_bound]. Default: 1.0\n",
    "  'saturation_factor_upper_bound': 1.33,\n",
    "  # Apply random left/right flip. Default: False\n",
    "  'horizontal_flip': True,\n",
    "  # Apply random up/down flip. Default: False\n",
    "  'vertical_flip': True,\n",
    "  # Apply random number of 90 degree rotations. Default: False\n",
    "  'rotate90': True,\n",
    "  \n",
    "}\n",
    "tr_preprocessing_fn = functools.partial(_augment, **tr_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RtzLkDFMpF0T"
   },
   "outputs": [],
   "source": [
    "val_cfg = {\n",
    "  'resize': [img_shape[0], img_shape[1]],\n",
    "  'scale': 1 / 255.,\n",
    "}\n",
    "val_preprocessing_fn = functools.partial(_augment, **val_cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Yasuvr5IbFlM"
   },
   "source": [
    "### Debug Output: Preprocessing pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hjoUqbPdHQej"
   },
   "outputs": [],
   "source": [
    "if DEBUG_OUTPUT:\n",
    "  temp_ds = get_baseline_dataset(x_train_filenames, \n",
    "                               y_train_filenames,\n",
    "                               preproc_fn=tr_preprocessing_fn,\n",
    "                               batch_size=1,\n",
    "                               shuffle=False)\n",
    "  # Let's examine some of these augmented images\n",
    "  data_aug_iter = temp_ds.make_one_shot_iterator()\n",
    "  next_element = data_aug_iter.get_next()\n",
    "  with tf.Session() as sess: \n",
    "    batch_of_imgs, label = sess.run(next_element)\n",
    "\n",
    "    # Running next element in our graph will produce a batch of images\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    img = batch_of_imgs[0]\n",
    "    label = label[0, :, :, 0]\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(img)\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(label, cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define losses\n",
    "Dice loss is a metric that measures overlap. More info on optimizing for Dice coefficient (our dice loss) can be found in the [paper](http://campar.in.tum.de/pub/milletari2016Vnet/milletari2016Vnet.pdf), where it was introduced. \n",
    "\n",
    "We use dice loss here because it performs better at class imbalanced problems by design. In addition, maximizing the dice coefficient and IoU metrics are the actual objectives and goals of our segmentation task. Using cross entropy is more of a proxy which is easier to maximize. Instead, we maximize our objective directly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t_8_hbHECUAW"
   },
   "outputs": [],
   "source": [
    "def dice_coeff(y_true, y_pred):\n",
    "  smooth = 1.0\n",
    "  intersection = tf.reduce_sum(y_true * y_pred)\n",
    "  score = (2. * intersection + smooth) / (tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) + smooth)\n",
    "  return score\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "  loss = 1 - dice_coeff(y_true, y_pred)\n",
    "  return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qqClGNFJdANU"
   },
   "source": [
    "Here, we'll use a specialized loss function that combines binary cross entropy and our dice loss. This is based on [individuals who competed within this competition obtaining better results empirically](https://www.kaggle.com/c/carvana-image-masking-challenge/discussion/40199). Try out your own custom losses to measure performance (e.g. bce + log(dice_loss), only bce, etc.)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_crossentropy(y_true, y_pred):\n",
    "  return losses.binary_crossentropy(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def root_mean_squared_error(y_true, y_pred):\n",
    "  loss = tf.sqrt(losses.mean_squared_error(y_true, y_pred))\n",
    "  return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implementation taken from https://lars76.github.io/neural-networks/object-detection/losses-for-segmentation/\n",
    "# \n",
    "def tversky_loss(beta=0.5):\n",
    "  def loss(y_true, y_pred):\n",
    "    numerator = tf.reduce_sum(y_true * y_pred)\n",
    "    false_positives = (1.0 - y_true) * y_pred\n",
    "    false_negatives = y_true * (1.0 - y_pred)\n",
    "    denominator = y_true * y_pred + beta * false_positives + (1 - beta) * false_negatives\n",
    "\n",
    "    return numerator / (tf.reduce_sum(denominator) + tf.keras.backend.epsilon())\n",
    "\n",
    "  return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "udrfi9JGB-bL"
   },
   "outputs": [],
   "source": [
    "def loss_fn(y_true, y_pred):\n",
    "  # Flatten\n",
    "  y_true = tf.reshape(y_true, [-1])\n",
    "  y_pred = tf.reshape(y_pred, [-1])\n",
    "  \n",
    "  #loss = binary_crossentropy(y_true, y_pred)\n",
    "  #loss = dice_loss(y_true, y_pred)\n",
    "  loss = binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n",
    "  #loss = 1/24.0 * binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred) + root_mean_squared_error(y_true, y_pred) + tversky_loss(0.2)(y_true, y_pred)\n",
    "  \n",
    "  return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define our neural network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zfew1i1F6bK-"
   },
   "outputs": [],
   "source": [
    "def conv_block(input_tensor, num_filters, dilation_rate=1, apply_last_activation=True):\n",
    "  layer = input_tensor\n",
    "  layer = layers.Conv2D(num_filters, (3, 3), padding='same', dilation_rate=dilation_rate)(layer)\n",
    "  layer = layers.Lambda(tf.contrib.layers.layer_norm)(layer)\n",
    "  layer = layers.Activation('relu')(layer)\n",
    "  layer = layers.Conv2D(num_filters, (3, 3), padding='same', dilation_rate=dilation_rate)(layer)\n",
    "  layer = layers.Lambda(tf.contrib.layers.layer_norm)(layer)\n",
    "  if apply_last_activation:\n",
    "    layer = layers.Activation('relu')(layer)\n",
    "  return layer\n",
    "\n",
    "def residual_block(input_tensor, num_filters, dilation_rate=1):\n",
    "  # Shape of input_tensor: [batch_size, height, width, num_channels]\n",
    "  _, _, _, num_channels = input_tensor.shape\n",
    "  layer = conv_block(input_tensor, num_filters, dilation_rate=dilation_rate)\n",
    "  # Apply projection if num_filters are not equal\n",
    "  if num_filters != num_channels:\n",
    "    input_tensor = layers.Conv2D(num_filters, (1, 1), padding='same')(input_tensor)  \n",
    "  layer = layers.Add()([input_tensor, layer])\n",
    "  return layer\n",
    "\n",
    "def residual_bottleneck_block(input_tensor, num_filters, num_channels=256, dilation_rate=1):\n",
    "  # Shape of input_tensor: [batch_size, height, width, num_channels]\n",
    "  layer = layers.Conv2D(num_filters, (1, 1), padding='same')(input_tensor)\n",
    "  layer = layers.Lambda(tf.contrib.layers.layer_norm)(layer)\n",
    "  layer = layers.Activation('relu')(layer)\n",
    "  layer = layers.Conv2D(num_filters, (3, 3), padding='same', dilation_rate=dilation_rate)(layer)\n",
    "  layer = layers.Lambda(tf.contrib.layers.layer_norm)(layer)\n",
    "  layer = layers.Activation('relu')(layer)\n",
    "  layer = layers.Dropout(0.25)(layer)\n",
    "  # restore num_channels\n",
    "  layer = layers.Conv2D(num_channels, (1, 1), padding='same')(layer)\n",
    "  layer = layers.Lambda(tf.contrib.layers.layer_norm)(layer)\n",
    "  layer = layers.Activation('relu')(layer)  \n",
    "  layer = layers.Add()([input_tensor, layer])\n",
    "  return layer\n",
    "\n",
    "def dilated_spatial_pyramid_pooling(input_tensor, num_filters, num_filters_out=256, dilation_rates=[1]):\n",
    "  to_concat = []\n",
    "  to_concat.append(layers.Conv2D(num_filters, (1, 1), padding='same')(input_tensor))\n",
    "  for d in dilation_rates:\n",
    "    to_concat.append(layers.Conv2D(num_filters, (3, 3), padding='same', dilation_rate=d)(input_tensor))  \n",
    "  output = layers.Concatenate(axis=-1)(to_concat)\n",
    "  output = layers.Conv2D(num_filters_out, (1, 1), padding='same')(output)\n",
    "  output = layers.Dropout(0.25)(output)\n",
    "  return output\n",
    "\n",
    "def encoder_block(input_tensor, num_filters, num_blocks=1):\n",
    "  layer = input_tensor\n",
    "  layer = residual_block(layer, num_filters, dilation_rate=1)\n",
    "  #layer = residual_block(layer, num_filters, dilation_rate=1)\n",
    "  #layer = residual_block(layer, num_filters, dilation_rate=1)\n",
    "  pooled = layers.MaxPooling2D((2, 2), strides=(2, 2))(layer)\n",
    "  #pooled = dilated_spatial_pyramid_pooling(pooled, num_filters, dilation_rates=[1,2,5])\n",
    "  return pooled, layer\n",
    "\n",
    "def decoder_block(input_tensor, concat_tensor, num_filters, num_filters_out=256):\n",
    "  layer = layers.Conv2DTranspose(num_filters, (2, 2), strides=(2, 2), padding='same')(input_tensor)\n",
    "  layer = layers.Concatenate(axis=-1)([concat_tensor, layer])\n",
    "  layer = layers.Lambda(tf.contrib.layers.layer_norm)(layer)\n",
    "  layer = layers.Activation('relu')(layer)\n",
    "  layer = residual_block(layer, num_filters, dilation_rate=1)\n",
    "  #layer = residual_block(layer, num_filters, dilation_rate=1)\n",
    "  #layer = residual_block(layer, num_filters, dilation_rate=1)\n",
    "  return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xRLp21S_hpTn"
   },
   "outputs": [],
   "source": [
    "def createInputsOutputs():\n",
    "  inputs = layers.Input(shape=img_shape)\n",
    "  # 256\n",
    "  encoder0_pool, encoder0 = encoder_block(inputs, 32)\n",
    "  # 128\n",
    "  encoder1_pool, encoder1 = encoder_block(encoder0_pool, 64)\n",
    "  # 64\n",
    "  encoder2_pool, encoder2 = encoder_block(encoder1_pool, 128)\n",
    "  # 32\n",
    "  encoder3_pool, encoder3 = encoder_block(encoder2_pool, 256)\n",
    "  # 16\n",
    "  encoder4_pool, encoder4 = encoder_block(encoder3_pool, 512)\n",
    "  # 8\n",
    "  center = conv_block(encoder4_pool, 1024)\n",
    "  # center\n",
    "  decoder4 = decoder_block(center, encoder4, 512)\n",
    "  # 16\n",
    "  decoder3 = decoder_block(decoder4, encoder3, 256)\n",
    "  # 32\n",
    "  decoder2 = decoder_block(decoder3, encoder2, 128)\n",
    "  # 64\n",
    "  decoder1 = decoder_block(decoder2, encoder1, 64)\n",
    "  # 128\n",
    "  decoder0 = decoder_block(decoder1, encoder0, 32)\n",
    "  # 256\n",
    "  outputs = layers.Conv2D(1, (1, 1), activation='sigmoid')(decoder0)\n",
    "  return inputs, outputs\n",
    "\n",
    "def createCompiledModel():\n",
    "  inputs, outputs = createInputsOutputs()\n",
    "  model = models.Model(inputs=[inputs], outputs=[outputs])\n",
    "  model.compile(optimizer=tf.keras.optimizers.Adam(1e-4), \n",
    "                loss=loss_fn, \n",
    "                metrics=[binary_crossentropy, root_mean_squared_error, dice_loss])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model path\n",
    "model_time = time.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "model_path = 'runs/' + str(model_time) + '/'\n",
    "os.makedirs(model_path, exist_ok=True)\n",
    "print('Set model dir to: ' + model_path)\n",
    "\n",
    "# Copy *.py and *.ipynb files to model_path (save source code)\n",
    "\n",
    "cwd = os.getcwd()\n",
    "for file in glob.glob(os.path.join(cwd, '*.py')):\n",
    "  shutil.copy2(file, model_path)\n",
    "for file in glob.glob(os.path.join(cwd, '*.ipynb')):\n",
    "  shutil.copy2(file, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1nHnj6199elZ"
   },
   "outputs": [],
   "source": [
    "sess = tf.Session(config=tf.ConfigProto(intra_op_parallelism_threads=4, allow_soft_placement=True))\n",
    "tf.keras.backend.set_session(sess)\n",
    "\n",
    "model = createCompiledModel()\n",
    "model.save(model_path + 'model.hdf5')\n",
    "model.summary()\n",
    "\n",
    "tf.keras.backend.get_session().close()\n",
    "del model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vJP_EvuTb4hH"
   },
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UMZcOrq5aaj1",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "histories = []\n",
    "cv = 0\n",
    "\n",
    "for trainIndices, valIndices in data_splits:\n",
    "  cv = cv + 1\n",
    "  if cv_splits > 1:\n",
    "    print(\"Cross validation round {} of {}\".format(cv, cv_splits))\n",
    "  save_model_path = model_path + 'weights_cv' + str(cv) + '_epoch{epoch:03d}_rmse{val_root_mean_squared_error:.4f}.hdf5'\n",
    "  \n",
    "  train_ds = get_baseline_dataset(x_train_filenames[trainIndices], \n",
    "                                  y_train_filenames[trainIndices],\n",
    "                                  preproc_fn=tr_preprocessing_fn,\n",
    "                                  batch_size=batch_size)\n",
    "  val_ds = get_baseline_dataset(x_train_filenames[valIndices], \n",
    "                                y_train_filenames[valIndices],\n",
    "                                preproc_fn=val_preprocessing_fn,\n",
    "                                batch_size=batch_size)\n",
    "  \n",
    "  sess = tf.Session(config=tf.ConfigProto(intra_op_parallelism_threads=4, allow_soft_placement=True))\n",
    "  tf.keras.backend.set_session(sess)\n",
    "  \n",
    "  # Create model\n",
    "  model = createCompiledModel()\n",
    "  sess.run(tf.initializers.global_variables())\n",
    "  # Create callbacks\n",
    "  tb = TrainValTensorBoard(log_dir=model_path)\n",
    "  cp = tf.keras.callbacks.ModelCheckpoint(filepath=save_model_path, monitor='val_loss', save_weights_only=True, save_best_only=True, verbose=1)\n",
    "  es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0.005, patience=15, verbose=1, mode='auto')\n",
    "  # Train model\n",
    "  history = model.fit(train_ds, \n",
    "                    steps_per_epoch=int(np.ceil(len(x_train_filenames[trainIndices]) / float(batch_size))),\n",
    "                    epochs=epochs,\n",
    "                    validation_data=val_ds,\n",
    "                    validation_steps=int(np.ceil(len(x_train_filenames[valIndices]) / float(batch_size))),\n",
    "                    callbacks=[tb, cp, es])\n",
    "  histories.append(history)\n",
    "  \n",
    "  del model\n",
    "  tf.keras.backend.get_session().close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AvntxymYn8rM",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n = len(histories)\n",
    "metrics = ['loss', 'root_mean_squared_error', 'dice_loss', 'binary_crossentropy']\n",
    "metric_count = len(metrics)\n",
    "\n",
    "plt.figure(figsize=(5*metric_count, 5*n))\n",
    "for i in range(n):\n",
    "  for m, metric in enumerate(metrics):\n",
    "    loss = histories[i].history[metric]\n",
    "    val_loss = histories[i].history['val_' + metric]\n",
    "    argmin_val_loss = np.argmin(val_loss)\n",
    "    epochs_range = range(len(loss))\n",
    "\n",
    "    plt.subplot(n, metric_count, (i*metric_count)+m+1)\n",
    "    plt.axvline(argmin_val_loss, color='#ff0000a0')\n",
    "    plt.plot(epochs_range, loss, label='Training', color='#ff6f42')\n",
    "    plt.plot(epochs_range, val_loss, label='Validation', color='#4184f3')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.title(metric + ', model' + str(i))\n",
    "\n",
    "plt.savefig(model_path + 'loss_graph.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MGFKf8yCTYbw"
   },
   "source": [
    "# Qualitative evaluation of our performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5Ph7acmrCXm6"
   },
   "outputs": [],
   "source": [
    "# Load weights from latest checkpoint\n",
    "weights_path = sorted(glob.glob(model_path + 'weights*'), reverse=True)[0]\n",
    "# Alternatively, set weight file directly\n",
    "#weights_path = \"runs/2019-06-21_16-38-37/weights_rmse0.1060_cv1_epoch084.hdf5\"\n",
    "\n",
    "# Create model again and initialize session.\n",
    "model = createCompiledModel()\n",
    "sess = tf.Session(config=tf.ConfigProto(intra_op_parallelism_threads=4, allow_soft_placement=True))\n",
    "tf.keras.backend.set_session(sess)\n",
    "sess.run(tf.initializers.global_variables())\n",
    "\n",
    "model.load_weights(weights_path)\n",
    "print(\"Loaded model weights from:\", weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0GnwZ7CPaamI",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Visualize some of the outputs \n",
    "num_display=4\n",
    "colored_masks=True\n",
    "\n",
    "data_aug_iter = val_ds.make_one_shot_iterator()\n",
    "next_element = data_aug_iter.get_next()\n",
    "cols=3\n",
    "\n",
    "# Running next element in our graph will produce a batch of images\n",
    "plt.figure(figsize=(5*cols, 5*num_display))\n",
    "for i in range(num_display):\n",
    "  batch_of_imgs, label = tf.keras.backend.get_session().run(next_element)\n",
    "  img = np.array(batch_of_imgs[0])\n",
    "  label = np.array(label[0, :, :, 0])\n",
    "  predicted_label = np.array(model.predict(batch_of_imgs)[0, :, :, 0])\n",
    "\n",
    "  plt.subplot(num_display, cols, cols * i + 1)\n",
    "  plt.imshow(img)\n",
    "  plt.title(\"Input image\")\n",
    "  \n",
    "  if colored_masks:\n",
    "    tp = label * predicted_label\n",
    "    fp = np.abs(tp - predicted_label)\n",
    "    fn = np.abs(tp - label)\n",
    "    plt.subplot(num_display, cols, cols * i + 2)\n",
    "    label = np.stack([fn, tp, 0.0*tp], axis=2)\n",
    "    plt.imshow(label)\n",
    "    plt.title(\"Actual Mask (false negatives in red)\")\n",
    "    plt.subplot(num_display, cols, cols * i + 3)\n",
    "    predicted_label = np.stack([fp , tp, 0.0*tp], axis=2)\n",
    "    plt.imshow(predicted_label)\n",
    "    plt.title(\"Predicted Mask (false positives in red)\")\n",
    "  \n",
    "  else:\n",
    "    plt.subplot(num_display, cols, cols * i + 2)\n",
    "    plt.imshow(label, cmap=\"gray\")\n",
    "    plt.title(\"Actual Mask\")\n",
    "    plt.subplot(num_display, cols, cols * i + 3)\n",
    "    plt.imshow(predicted_label, cmap=\"gray\")\n",
    "    plt.title(\"Predicted Mask\")\n",
    "  \n",
    "#plt.suptitle(\"Examples of Input Image, Label, and Prediction\")\n",
    "plt.savefig(model_path + 'validation_examples.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create test set predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create directory for predictions\n",
    "prediction_dir = weights_path.replace(\"weights\", \"predictions\", 1).replace(\".hdf5\", \"\", 1)\n",
    "os.mkdir(prediction_dir)\n",
    "\n",
    "test_ds = get_baseline_dataset(x_test_filenames,\n",
    "                               x_test_filenames, \n",
    "                               preproc_fn=val_preprocessing_fn,\n",
    "                               batch_size=batch_size,\n",
    "                               shuffle=False,\n",
    "                               repeat=False)\n",
    "\n",
    "data_aug_iter = test_ds.make_one_shot_iterator()\n",
    "next_element = data_aug_iter.get_next()\n",
    "count=0\n",
    "\n",
    "sess = tf.keras.backend.get_session()\n",
    "try:\n",
    "  while True:\n",
    "    batch_of_imgs, label = sess.run(next_element)\n",
    "    predicted_labels = model.predict(batch_of_imgs)\n",
    "    \n",
    "    # rescale images from [0, 1] to [0, 255]\n",
    "    predicted_labels = predicted_labels / val_cfg['scale']\n",
    "\n",
    "    for i in range(len(predicted_labels)):\n",
    "      pred = Image.fromarray(predicted_labels[i, :, :, 0], 'F').resize((608, 608)).convert('L')\n",
    "      imageio.imwrite(os.path.join(prediction_dir, test_filenames[count]), pred)\n",
    "      count += 1\n",
    "\n",
    "except tf.errors.OutOfRangeError:\n",
    "  pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show some of the predictions\n",
    "display_num = 4\n",
    "\n",
    "r_choices = np.random.choice(len(test_filenames), display_num)\n",
    "plt.figure(figsize=(10, 5*display_num))\n",
    "\n",
    "for i in range(0, display_num * 2, 2):\n",
    "  img_num = r_choices[i // 2]\n",
    "  x_pathname = x_test_filenames[img_num]\n",
    "  y_pathname = os.path.join(prediction_dir, test_filenames[img_num])\n",
    "\n",
    "  plt.subplot(display_num, 2, i + 1)\n",
    "  plt.imshow(mpimg.imread(x_pathname), cmap=\"gray\")  \n",
    "  plt.subplot(display_num, 2, i + 2)\n",
    "  plt.imshow(mpimg.imread(y_pathname), cmap=\"gray\")\n",
    "\n",
    "#plt.suptitle(\"Examples of images and their predicted segmentations\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mask to submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foreground_threshold = 0.25 # percentage of pixels > 1 required to assign a foreground label to a patch\n",
    "\n",
    "# assign a label to a patch\n",
    "def patch_to_label(patch):\n",
    "  df = np.mean(patch)\n",
    "  if df > foreground_threshold:\n",
    "    return 1\n",
    "  else:\n",
    "    return 0\n",
    "\n",
    "\n",
    "def mask_to_submission_strings(image_filename):\n",
    "  \"\"\"Reads a single image and outputs the strings that should go into the submission file\"\"\"\n",
    "  img_number = int(re.search(r\"\\d+(?=\\.png$)\", image_filename).group(0))\n",
    "  im = mpimg.imread(image_filename)\n",
    "  patch_size = 16\n",
    "  for j in range(0, im.shape[1], patch_size):\n",
    "    for i in range(0, im.shape[0], patch_size):\n",
    "      patch = im[i:i + patch_size, j:j + patch_size]\n",
    "      label = patch_to_label(patch)\n",
    "      yield(\"{:03d}_{}_{},{}\".format(img_number, j, i, label))\n",
    "\n",
    "\n",
    "def masks_to_submission(submission_filename, *image_filenames):\n",
    "  \"\"\"Converts images into a submission file\"\"\"\n",
    "  with open(submission_filename, 'w') as f:\n",
    "    f.write('id,prediction\\n')\n",
    "    for fn in image_filenames[0:]:\n",
    "      f.writelines('{}\\n'.format(s) for s in mask_to_submission_strings(fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_filename = weights_path.replace(\"weights\", \"submission\", 1).replace(\".hdf5\", \".csv\", 1)\n",
    "image_filenames = [os.path.join(prediction_dir, filename) for filename in os.listdir(prediction_dir)]\n",
    "masks_to_submission(submission_filename, *image_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Validating submission file:\", submission_filename)\n",
    "df = pd.read_csv(submission_filename)\n",
    "\n",
    "print('Shape of csv:', df.shape)\n",
    "assert df.shape == (135736, 2), \"Invalid number of rows or columns in submission file!\"\n",
    "assert df['id'].unique().size == 135736, \"Column 'id' should contain 135736 unique values!\"\n",
    "\n",
    "meanPred = df['prediction'].mean()\n",
    "print(\"Mean prediction: {:.3f}\".format(meanPred))\n",
    "assert meanPred > 0.05 and meanPred < 0.35, \"Very unlikely mean prediction!\"\n",
    "\n",
    "print(\"Submission file looks OKAY!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Image Segmentation",
   "private_outputs": true,
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
